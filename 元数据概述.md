# 元数据概述

## 元数据定义

​	元数据是关于数据的组织、数据域及其关系的信息，简言之，元数据就是关于数据的数据

> 类比：传统小说往往关心的是人物、事件，是作品所叙述的内容；而元小说则更关心作者本人是怎样写这部小说的，小说中往往喜欢声明作者是在虚构作品，喜欢告诉读者作者是在用什么手法虚构作品，更喜欢交代作者创作小说的一切相关过程。

​	元数据从信息资源中抽取出来用于说明其特征，内容的结构化的数据，用于组织，描述，检索，保存，管理信息和资源。

> 比如，关于一本书(信息资源）,可以在图书馆系统中检索出题名，作者，出版社，出版日期，附注，ISBN。一个基本的元数据由元数据项目和元数据内容构成，在这里题名(key)就相当于其元数据项目，"史蒂夫著"(value)就相当于元数据内容

​	每个人都可以对资源进行描述，元数据项目和元数据内容会千奇百怪，于是有了元数据标准。元数据标准包括元数据结构标准(即元数据包含那些项目，都柏林核心集，MARC元素集)，元数据内容标准，元数据取值标准，元数据编码标准(用于机读记录的存储和交换，比如MARC(Machine Readable Cataloging), XML)，现在一般使用XML

## 元数据目的

​	管理这些附加MetaData信息的目的，一方面是为了让用户能够更高效的挖掘和使用数据，另一方面是为了让平台管理人员能更加有效的做好系统的维护管理工作。

## 功能模块

### 元数据管理

- 定义：元数据管理包括业务词汇表的发展，数据元素和实体的定义，业务规则和算法以及数据特征。最基础的是管理业务元数据的收集，组织和维持。
- 工作流程：1、元数据管理平台首先最重要的是收集数据信息，没有数据就无从分析。而收集什么信息与业务需求有关。2、然后元数据管理平台还需要考虑如何以恰当的形式对这些元数据进行展示。3、将元数据信息通过服务的形式提供给周边上下游系统使用
- 常见的元数据信息包括：数据的表结构Schema信息，数据的空间存储、读写记录、权限归属和其它各类统计信息，数据的血缘关系信息，数据的业务属性信息

#### 数据的表结构Schema信息

​	数据的表结构信息，这个很容易理解了，狭义的元数据信息通常多半指的就是这部分内容了，它也的确属于元数据信息管理系统中最重要的一块内容。

​	不过，无论是SQL还是NoSQL的数据存储组件，多半自身都有管理和查询表格Schema的能力，这也很好理解如果没有这些能力的话，这些系统自身就没法良好的运转下去了不是。比如，Hive自身的表结构信息本来就存储在外部DB数据库中，Hive也提供类似 show table，describe table之类的语法对这些信息进行查询。那么我们为什么还要多此一举，再开发一个元数据管理系统对这些信息进行管理呢？

​	这么做，可能的理由很多，需要集中管理可以是其中一个理由，但更重要的理由，是因为本质上，这些系统自身的元数据信息管理手段通常都是为了满足系统自身的功能运转而设计的。也就是说，它们并不是为了数据质量管理的目的而存在的，由于需求定位不同，所以无论从功能形态还是从交互手段的角度来说，它们通常也就无法直接满足数据质量管理的需求。

​	举个很简单的例子，比如我想知道表结构的历史变迁记录，很显然多数系统自身是不会设计这样的功能的。而且一些功能就算有，周边上下游的其它业务系统往往也不适合直接从该系统中获取这类信息，因为如果那样做的话，系统的安全性和相互直接的依赖耦合往往都会是个问题。

#### 数据的空间存储、读写记录、权限归属和其它各类统计信息

​	这类信息，可能包括但不限于：数据占据了多少底层存储空间，最近是否有过修改，都有谁在什么时候使用过这些数据，谁有权限管理和查阅这些数据等等。此外，还可以包括类似昨天新增了多少个表格，删除了多少表格，创建了多少分区之类的统计信息。

 #### 数据的血缘关系信息

​	简单的说就是数据之间的上下游来源去向关系，数据从哪里来到哪里去。

​	如果一个数据有问题，你可以根据血缘关系往上游排查，看看到底在哪个环节出了问题。此外我们也可以通过数据的血缘关系，建立起生产这些数据的任务之间的依赖关系，进而辅助调度系统的工作调度，或者用来判断一个失败或错误的任务可能对哪些下游数据造成影响等等。

​	一般可以通过分析日志信息来粗略判断目录级别的读写关系，甚至可以通过分析脚本的执行计划来相对精确的定位血缘关系。

#### 数据的业务属性信息

​	业务属性信息都有哪些呢？最常见的，比如，一张数据表的统计口径信息，这张表干什么用的，各个字段的具体统计方式，业务描述，业务标签，脚本逻辑的历史变迁记录，变迁原因等等，此外，你也可能会关心对应的数据表格是由谁负责开发的，具体数据的业务部门归属等等。

​	尽管这部分信息往往需要通过外部手段人工录入，但是还是需要尽量考虑和流程进行整合，让它们成为业务开发必不可少的环节。比如，一部分信息的采集，可以通过整体数据平台的开发流程规范，嵌入到对应数据的开发过程中进行，例如历史变迁记录可以在修改任务脚本或者表格schema时强制要求填写；业务负责人信息，可以通过当前开发人员的业务线和开发群组归属关系自动进行映射填充；字段统计方式信息，尽可能通过标准的维度指标管理体系进行规范定义。

#### 元数据管理相关系统方案介绍

- Apache Atlas
- Cloudera Navigator Data Management

### 数据质量管理

#### 数据质量管理大致流程

​	对数据在整个生命周期中的质量进行全程监控，利用检测规则及时发现问题，并通过元数据信息，实现拓扑呈现，提供系统数据处理状态和质量状况的全局报告，帮助数据管理人员分析问题，解决问题。元数据管理为数据质量提供各种检核规则，数据质量进行数据检核，生成检核结果，结合数据标准和元数据管理进行数据的修改，以保证最后数据的统一，从根源上提高系统数据质量。

#### 数据存在的问题

- 信息问题：缺乏统一的数据描述导致业务理解差异；信息标准不统一产生低质量的数据，导致业务人员对数据缺乏信心。
- 管理问题：对数据质量的价值及其重要性认识不足；缺乏专门的数据质量管理组织与相关的管理制度。
- 流程问题：需求变更、开发测试等方面没有流程规范和制度；数据创建、数据使用、数据维护等方面没有流程规范和制度。
- 技术问题：系统建设重功能轻数据；系统接口复杂；数据流向不清，缺乏对数据的整体规划；具体数据处理的各技术的异常造成的数据质量问题。

#### 数据质量度量规则

- 完整性：主要包括实体不缺失、属性不缺失、记录不缺失和字段不缺失四个方面。
- 有效性：对每个数据元素的有效值做出详细描述，然后检核数据是否符合有效性的需求。
- 唯一性：指主键唯一和候选键唯一两方面。
- 一致性：指统一数据来源、统一存储和统一数据口径。
- 准确性：指计量误差、度量单位等方面的精确程度。
- 合理性：主要包括格式、类型和业务规则的有效性。
- 及时性：指数据刷新、修改和提取等操作的及时性和快速性。

#### 数据质量探查及分析

​	需要指定数据质量探查和评估方法，以便初步了解和掌握源数据的数据质量问题，是数据质量保障的基础。

​	数据质量探查主要从以下四个方面对字段进行探查：

- 值域分析（列内容分布探查）

- 完整性分析（空值探查、数值合法性探查、极限值探查、数值大于0探查、数值小于0探查、数值为0探查）

- 有效性分析（日期合法性探查、换行字符探查、回车字符探查、全角字符探查）

- 结构整体性分析（字段重复性探查[业务主键]）

  数据质量探查结果按照表级和字段级分别展示。表级给出表整体概述，字段级给出具体的探查行为与结果。

#### 数据质量管理策略

- 数据质量指标
- 质量检核运行
- 质量问题报警
- 质量问题分析
- 问题管理流程

#### 数据质量管理关键点

- 制定规范的数据质量度量标准
- 建立有效的数据质量监管体系
- 建立完善的数据质量管理制度

### 数据生命周期

​	数据生命周期管理是一种基于策略的方法，用于管理信息系统的数据在整个生命周期内的流动：从创建和初始存储，到它过时被删除。

​	数据生命周期管理框架由数据归类、数据特性分析与数据存储策略三部分组成。数据存储框架首先对数据进行归类，在数据归类的基础上结合业务与系统实际情况，分析数据特性，最后根据现状调研、数据归类与数据特性制定数据生命周期存储策略，从而保障数据存储策略能够更加符合业务、系统的实际需求，有效的发挥数据生命周期管理的价值。

### ETL

​	ETL，是英文 Extract-Transform-Load 的缩写，用来描述将数据从来源端经过萃取（extract）、转置（transform）、加载（load）至目的端的过程。ETL一词较常用在数据仓库，但其对象并不限于数据仓库。

​	ETL过程中的主要环节就是数据抽取、数据转换和加工、数据装载。为了实现这些功能，各个ETL工具一般会进行一些功能上的扩充，例如工作流、调度引擎、规则引擎、脚本支持、统计信息等。	





